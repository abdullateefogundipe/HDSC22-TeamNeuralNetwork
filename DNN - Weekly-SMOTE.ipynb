{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0be5f70",
   "metadata": {},
   "source": [
    "# Importing the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fd236b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import tempfile\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22ea679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (15, 18)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de7a39c",
   "metadata": {},
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cefaf45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nr. sessions</th>\n",
       "      <th>nr. rest days</th>\n",
       "      <th>total kms</th>\n",
       "      <th>max km one day</th>\n",
       "      <th>total km Z3-Z4-Z5-T1-T2</th>\n",
       "      <th>nr. tough sessions (effort in Z5, T1 or T2)</th>\n",
       "      <th>nr. days with interval session</th>\n",
       "      <th>total km Z3-4</th>\n",
       "      <th>max km Z3-4 one day</th>\n",
       "      <th>total km Z5-T1-T2</th>\n",
       "      <th>...</th>\n",
       "      <th>max training success.2</th>\n",
       "      <th>avg recovery.2</th>\n",
       "      <th>min recovery.2</th>\n",
       "      <th>max recovery.2</th>\n",
       "      <th>Athlete ID</th>\n",
       "      <th>injury</th>\n",
       "      <th>rel total kms week 0_1</th>\n",
       "      <th>rel total kms week 0_2</th>\n",
       "      <th>rel total kms week 1_2</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.2</td>\n",
       "      <td>16.4</td>\n",
       "      <td>11.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.718447</td>\n",
       "      <td>1.378882</td>\n",
       "      <td>1.919255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>16.4</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.683544</td>\n",
       "      <td>1.018868</td>\n",
       "      <td>1.490566</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>16.4</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.683544</td>\n",
       "      <td>1.018868</td>\n",
       "      <td>1.490566</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>16.4</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.683544</td>\n",
       "      <td>1.018868</td>\n",
       "      <td>1.490566</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.2</td>\n",
       "      <td>17.6</td>\n",
       "      <td>18.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.202247</td>\n",
       "      <td>1.361111</td>\n",
       "      <td>0.618056</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   nr. sessions  nr. rest days  total kms  max km one day  \\\n",
       "0             5            2.0       22.2            16.4   \n",
       "1             5            2.0       21.6            16.4   \n",
       "2             5            2.0       21.6            16.4   \n",
       "3             5            2.0       21.6            16.4   \n",
       "4             6            1.0       39.2            17.6   \n",
       "\n",
       "   total km Z3-Z4-Z5-T1-T2  nr. tough sessions (effort in Z5, T1 or T2)  \\\n",
       "0                     11.8                                          1.0   \n",
       "1                     11.7                                          1.0   \n",
       "2                     11.7                                          1.0   \n",
       "3                     11.7                                          1.0   \n",
       "4                     18.9                                          1.0   \n",
       "\n",
       "   nr. days with interval session  total km Z3-4  max km Z3-4 one day  \\\n",
       "0                             2.0           10.0                 10.0   \n",
       "1                             2.0           10.0                 10.0   \n",
       "2                             2.0           10.0                 10.0   \n",
       "3                             2.0           10.0                 10.0   \n",
       "4                             3.0           17.2                 10.0   \n",
       "\n",
       "   total km Z5-T1-T2  ...  max training success.2  avg recovery.2  \\\n",
       "0                0.6  ...                     0.0            0.18   \n",
       "1                0.5  ...                     0.0            0.18   \n",
       "2                0.5  ...                     0.0            0.17   \n",
       "3                0.5  ...                     0.0            0.18   \n",
       "4                0.5  ...                     0.0            0.17   \n",
       "\n",
       "   min recovery.2  max recovery.2  Athlete ID  injury  rel total kms week 0_1  \\\n",
       "0            0.16            0.20           0       0                0.718447   \n",
       "1            0.16            0.20           0       0                0.683544   \n",
       "2            0.16            0.18           0       0                0.683544   \n",
       "3            0.16            0.18           0       0                0.683544   \n",
       "4            0.16            0.18           0       0                2.202247   \n",
       "\n",
       "   rel total kms week 0_2  rel total kms week 1_2  Date  \n",
       "0                1.378882                1.919255     0  \n",
       "1                1.018868                1.490566     1  \n",
       "2                1.018868                1.490566     2  \n",
       "3                1.018868                1.490566     3  \n",
       "4                1.361111                0.618056     4  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = tf.keras.utils\n",
    "raw_df = pd.read_csv('week_approach_maskedID_timeseries.csv')\n",
    "convert_dict = {'nr. sessions': int } #convert nr.sessions to int \n",
    "raw_df = raw_df.astype(convert_dict)\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ff9ceb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "    Total: 42798\n",
      "    Positive: 575 (1.34% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This section displays the percentage of the majority class\n",
    "neg, pos = np.bincount(raw_df['injury'])\n",
    "total = neg + pos\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da3bf02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "42793    71\n",
       "42794    71\n",
       "42795    71\n",
       "42796    71\n",
       "42797    71\n",
       "Name: Athlete ID, Length: 42798, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping the unnecessary columns/features\n",
    "cleaned_df = raw_df.copy()\n",
    "cleaned_df.pop('Date')\n",
    "cleaned_df.pop('Athlete ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e71874d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleaned_df.drop('injury', axis = 1)\n",
    "y = cleaned_df['injury']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a5a64fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0190c649",
   "metadata": {},
   "source": [
    "# Applying Synthetic Minority Oversampling Technique (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33554ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is because the data is so imbalanced. The minority class is oversampled with new similar data is generated to compensate its minimal numbers\n",
    "smote_technique = SMOTE(sampling_strategy='minority')\n",
    "X_smt, y_smt = smote_technique.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c2d46da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    42223\n",
       "1    42223\n",
       "Name: injury, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_smt.value_counts() #class counts now match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa619a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data is split to Train and test \n",
    "X_train_smt, X_test_smt, y_train_smt, y_test_smt = train_test_split(X_smt, y_smt, test_size=0.3, random_state=15, stratify=y_smt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cc4aad",
   "metadata": {},
   "source": [
    "# Defining the Deep Nearal Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "498ae39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-19 21:37:28.374236: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "dnn_model = keras.Sequential([\n",
    "    keras.layers.Dense(16, input_shape=(X.shape[1],), activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(8, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    verbose=1,\n",
    "    patience=20,\n",
    "    mode='min',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e138507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bd525dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model compliation\n",
    "dnn_model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af316503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fe7e675f5f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1848/1848 [==============================] - 13s 5ms/step - loss: 9101.6182 - tp: 23925.0000 - fp: 21342.0000 - tn: 8214.0000 - fn: 5631.0000 - accuracy: 0.5437 - precision: 0.5285 - recall: 0.8095 - auc: 0.5488 - prc: 0.5260\n",
      "Epoch 2/300\n",
      "1848/1848 [==============================] - 6s 3ms/step - loss: 255.9767 - tp: 26531.0000 - fp: 23229.0000 - tn: 6327.0000 - fn: 3025.0000 - accuracy: 0.5559 - precision: 0.5332 - recall: 0.8977 - auc: 0.5810 - prc: 0.5472\n",
      "Epoch 3/300\n",
      "1848/1848 [==============================] - 6s 3ms/step - loss: 58.3451 - tp: 24537.0000 - fp: 20096.0000 - tn: 9460.0000 - fn: 5019.0000 - accuracy: 0.5751 - precision: 0.5498 - recall: 0.8302 - auc: 0.6072 - prc: 0.5673\n",
      "Epoch 4/300\n",
      "1848/1848 [==============================] - 6s 3ms/step - loss: 19.2955 - tp: 24895.0000 - fp: 18888.0000 - tn: 10668.0000 - fn: 4661.0000 - accuracy: 0.6016 - precision: 0.5686 - recall: 0.8423 - auc: 0.6333 - prc: 0.5852\n",
      "Epoch 5/300\n",
      "1848/1848 [==============================] - 6s 3ms/step - loss: 5.5062 - tp: 24986.0000 - fp: 18176.0000 - tn: 11380.0000 - fn: 4570.0000 - accuracy: 0.6152 - precision: 0.5789 - recall: 0.8454 - auc: 0.6495 - prc: 0.6011\n",
      "Epoch 6/300\n",
      "1848/1848 [==============================] - 5s 3ms/step - loss: 1.4756 - tp: 25151.0000 - fp: 18176.0000 - tn: 11380.0000 - fn: 4405.0000 - accuracy: 0.6180 - precision: 0.5805 - recall: 0.8510 - auc: 0.6543 - prc: 0.6030\n",
      "Epoch 7/300\n",
      "1848/1848 [==============================] - 5s 3ms/step - loss: 0.6936 - tp: 25378.0000 - fp: 17990.0000 - tn: 11566.0000 - fn: 4178.0000 - accuracy: 0.6250 - precision: 0.5852 - recall: 0.8586 - auc: 0.6603 - prc: 0.6069\n",
      "Epoch 8/300\n",
      "1848/1848 [==============================] - 6s 3ms/step - loss: 0.7289 - tp: 25309.0000 - fp: 17733.0000 - tn: 11823.0000 - fn: 4247.0000 - accuracy: 0.6282 - precision: 0.5880 - recall: 0.8563 - auc: 0.6651 - prc: 0.6115\n",
      "Epoch 9/300\n",
      "1848/1848 [==============================] - 6s 3ms/step - loss: 0.7061 - tp: 25555.0000 - fp: 17838.0000 - tn: 11718.0000 - fn: 4001.0000 - accuracy: 0.6305 - precision: 0.5889 - recall: 0.8646 - auc: 0.6667 - prc: 0.6125\n",
      "Epoch 10/300\n",
      "1848/1848 [==============================] - 7s 4ms/step - loss: 0.6251 - tp: 25777.0000 - fp: 17951.0000 - tn: 11605.0000 - fn: 3779.0000 - accuracy: 0.6324 - precision: 0.5895 - recall: 0.8721 - auc: 0.6708 - prc: 0.6124\n",
      "Epoch 11/300\n",
      "1848/1848 [==============================] - 8s 4ms/step - loss: 0.6640 - tp: 25719.0000 - fp: 17555.0000 - tn: 12001.0000 - fn: 3837.0000 - accuracy: 0.6381 - precision: 0.5943 - recall: 0.8702 - auc: 0.6760 - prc: 0.6188\n",
      "Epoch 12/300\n",
      "1848/1848 [==============================] - 13s 7ms/step - loss: 0.6303 - tp: 25704.0000 - fp: 17369.0000 - tn: 12187.0000 - fn: 3852.0000 - accuracy: 0.6410 - precision: 0.5968 - recall: 0.8697 - auc: 0.6803 - prc: 0.6215\n",
      "Epoch 13/300\n",
      "1848/1848 [==============================] - 7s 4ms/step - loss: 1.2147 - tp: 25665.0000 - fp: 17141.0000 - tn: 12415.0000 - fn: 3891.0000 - accuracy: 0.6442 - precision: 0.5996 - recall: 0.8684 - auc: 0.6828 - prc: 0.6251\n",
      "Epoch 14/300\n",
      "1848/1848 [==============================] - 6s 3ms/step - loss: 1.5908 - tp: 25377.0000 - fp: 16665.0000 - tn: 12891.0000 - fn: 4179.0000 - accuracy: 0.6474 - precision: 0.6036 - recall: 0.8586 - auc: 0.6856 - prc: 0.6259\n",
      "Epoch 15/300\n",
      "1848/1848 [==============================] - 6s 3ms/step - loss: 0.6083 - tp: 25765.0000 - fp: 16908.0000 - tn: 12648.0000 - fn: 3791.0000 - accuracy: 0.6498 - precision: 0.6038 - recall: 0.8717 - auc: 0.6899 - prc: 0.6322\n",
      "Epoch 16/300\n",
      "1848/1848 [==============================] - 9s 5ms/step - loss: 1.8730 - tp: 26131.0000 - fp: 17201.0000 - tn: 12355.0000 - fn: 3425.0000 - accuracy: 0.6511 - precision: 0.6030 - recall: 0.8841 - auc: 0.6932 - prc: 0.6321\n",
      "Epoch 17/300\n",
      "1848/1848 [==============================] - 6s 3ms/step - loss: 0.6668 - tp: 26237.0000 - fp: 17142.0000 - tn: 12414.0000 - fn: 3319.0000 - accuracy: 0.6539 - precision: 0.6048 - recall: 0.8877 - auc: 0.6980 - prc: 0.6381\n",
      "Epoch 18/300\n",
      "1848/1848 [==============================] - 6s 3ms/step - loss: 0.7534 - tp: 26149.0000 - fp: 16937.0000 - tn: 12619.0000 - fn: 3407.0000 - accuracy: 0.6558 - precision: 0.6069 - recall: 0.8847 - auc: 0.6960 - prc: 0.6350\n",
      "Epoch 19/300\n",
      "1848/1848 [==============================] - 8s 4ms/step - loss: 4.1706 - tp: 26000.0000 - fp: 16733.0000 - tn: 12823.0000 - fn: 3556.0000 - accuracy: 0.6568 - precision: 0.6084 - recall: 0.8797 - auc: 0.6990 - prc: 0.6404\n",
      "Epoch 20/300\n",
      "1848/1848 [==============================] - 9s 5ms/step - loss: 0.6071 - tp: 25924.0000 - fp: 16444.0000 - tn: 13112.0000 - fn: 3632.0000 - accuracy: 0.6604 - precision: 0.6119 - recall: 0.8771 - auc: 0.7025 - prc: 0.6425\n",
      "Epoch 21/300\n",
      "1848/1848 [==============================] - 6s 3ms/step - loss: 0.5951 - tp: 26028.0000 - fp: 16430.0000 - tn: 13126.0000 - fn: 3528.0000 - accuracy: 0.6624 - precision: 0.6130 - recall: 0.8806 - auc: 0.7070 - prc: 0.6472\n",
      "Epoch 22/300\n",
      "1848/1848 [==============================] - 6s 3ms/step - loss: 0.5940 - tp: 26235.0000 - fp: 16548.0000 - tn: 13008.0000 - fn: 3321.0000 - accuracy: 0.6639 - precision: 0.6132 - recall: 0.8876 - auc: 0.7083 - prc: 0.6488\n",
      "Epoch 23/300\n",
      "1848/1848 [==============================] - 6s 3ms/step - loss: 0.6504 - tp: 26271.0000 - fp: 16551.0000 - tn: 13005.0000 - fn: 3285.0000 - accuracy: 0.6644 - precision: 0.6135 - recall: 0.8889 - auc: 0.7113 - prc: 0.6514\n",
      "Epoch 24/300\n",
      "1848/1848 [==============================] - 9s 5ms/step - loss: 0.5942 - tp: 26319.0000 - fp: 16472.0000 - tn: 13084.0000 - fn: 3237.0000 - accuracy: 0.6666 - precision: 0.6151 - recall: 0.8905 - auc: 0.7122 - prc: 0.6507\n",
      "Epoch 25/300\n",
      "1848/1848 [==============================] - 9s 5ms/step - loss: 0.5878 - tp: 26397.0000 - fp: 16529.0000 - tn: 13027.0000 - fn: 3159.0000 - accuracy: 0.6669 - precision: 0.6149 - recall: 0.8931 - auc: 0.7136 - prc: 0.6536\n",
      "Epoch 26/300\n",
      "1848/1848 [==============================] - 7s 4ms/step - loss: 0.5839 - tp: 26632.0000 - fp: 16544.0000 - tn: 13012.0000 - fn: 2924.0000 - accuracy: 0.6707 - precision: 0.6168 - recall: 0.9011 - auc: 0.7164 - prc: 0.6543\n",
      "Epoch 27/300\n",
      "1848/1848 [==============================] - 7s 4ms/step - loss: 0.7806 - tp: 26395.0000 - fp: 16295.0000 - tn: 13261.0000 - fn: 3161.0000 - accuracy: 0.6709 - precision: 0.6183 - recall: 0.8931 - auc: 0.7191 - prc: 0.6587\n",
      "Epoch 28/300\n",
      "1848/1848 [==============================] - 6s 3ms/step - loss: 0.5804 - tp: 26619.0000 - fp: 16486.0000 - tn: 13070.0000 - fn: 2937.0000 - accuracy: 0.6714 - precision: 0.6175 - recall: 0.9006 - auc: 0.7200 - prc: 0.6581\n",
      "Epoch 29/300\n",
      "1848/1848 [==============================] - 7s 4ms/step - loss: 0.5991 - tp: 26660.0000 - fp: 16393.0000 - tn: 13163.0000 - fn: 2896.0000 - accuracy: 0.6737 - precision: 0.6192 - recall: 0.9020 - auc: 0.7234 - prc: 0.6625\n",
      "Epoch 30/300\n",
      "1848/1848 [==============================] - 6s 3ms/step - loss: 0.5793 - tp: 26628.0000 - fp: 16381.0000 - tn: 13175.0000 - fn: 2928.0000 - accuracy: 0.6733 - precision: 0.6191 - recall: 0.9009 - auc: 0.7220 - prc: 0.6605\n",
      "Epoch 31/300\n",
      "1848/1848 [==============================] - 6s 3ms/step - loss: 0.6275 - tp: 26671.0000 - fp: 16259.0000 - tn: 13297.0000 - fn: 2885.0000 - accuracy: 0.6761 - precision: 0.6213 - recall: 0.9024 - auc: 0.7267 - prc: 0.6666\n",
      "Epoch 32/300\n",
      "1848/1848 [==============================] - 6s 3ms/step - loss: 1.7665 - tp: 26560.0000 - fp: 16183.0000 - tn: 13373.0000 - fn: 2996.0000 - accuracy: 0.6755 - precision: 0.6214 - recall: 0.8986 - auc: 0.7244 - prc: 0.6635\n",
      "Epoch 33/300\n",
      "1848/1848 [==============================] - 5s 3ms/step - loss: 0.5752 - tp: 26607.0000 - fp: 16166.0000 - tn: 13390.0000 - fn: 2949.0000 - accuracy: 0.6766 - precision: 0.6221 - recall: 0.9002 - auc: 0.7297 - prc: 0.6727\n",
      "Epoch 34/300\n",
      "1848/1848 [==============================] - 5s 3ms/step - loss: 1.0002 - tp: 26559.0000 - fp: 16051.0000 - tn: 13505.0000 - fn: 2997.0000 - accuracy: 0.6778 - precision: 0.6233 - recall: 0.8986 - auc: 0.7282 - prc: 0.6686\n",
      "Epoch 35/300\n",
      "1848/1848 [==============================] - 5s 3ms/step - loss: 0.6175 - tp: 26376.0000 - fp: 15820.0000 - tn: 13736.0000 - fn: 3180.0000 - accuracy: 0.6786 - precision: 0.6251 - recall: 0.8924 - auc: 0.7299 - prc: 0.6716\n",
      "Epoch 36/300\n",
      "1848/1848 [==============================] - 8s 4ms/step - loss: 0.6074 - tp: 26434.0000 - fp: 15776.0000 - tn: 13780.0000 - fn: 3122.0000 - accuracy: 0.6803 - precision: 0.6262 - recall: 0.8944 - auc: 0.7303 - prc: 0.6725\n",
      "Epoch 37/300\n",
      "1848/1848 [==============================] - 7s 4ms/step - loss: 0.5737 - tp: 26400.0000 - fp: 15812.0000 - tn: 13744.0000 - fn: 3156.0000 - accuracy: 0.6791 - precision: 0.6254 - recall: 0.8932 - auc: 0.7307 - prc: 0.6718\n",
      "Epoch 38/300\n",
      "1848/1848 [==============================] - 9s 5ms/step - loss: 0.5822 - tp: 26574.0000 - fp: 15847.0000 - tn: 13709.0000 - fn: 2982.0000 - accuracy: 0.6815 - precision: 0.6264 - recall: 0.8991 - auc: 0.7308 - prc: 0.6717\n",
      "Epoch 39/300\n",
      "1848/1848 [==============================] - 13s 7ms/step - loss: 0.8426 - tp: 26607.0000 - fp: 16006.0000 - tn: 13550.0000 - fn: 2949.0000 - accuracy: 0.6793 - precision: 0.6244 - recall: 0.9002 - auc: 0.7291 - prc: 0.6690\n",
      "Epoch 40/300\n",
      "1848/1848 [==============================] - 13s 7ms/step - loss: 1.1944 - tp: 26525.0000 - fp: 15805.0000 - tn: 13751.0000 - fn: 3031.0000 - accuracy: 0.6814 - precision: 0.6266 - recall: 0.8974 - auc: 0.7313 - prc: 0.6718\n",
      "Epoch 41/300\n",
      "1848/1848 [==============================] - 10s 6ms/step - loss: 0.5748 - tp: 26364.0000 - fp: 15763.0000 - tn: 13793.0000 - fn: 3192.0000 - accuracy: 0.6793 - precision: 0.6258 - recall: 0.8920 - auc: 0.7302 - prc: 0.6710\n",
      "Epoch 42/300\n",
      "1848/1848 [==============================] - 17s 9ms/step - loss: 0.7364 - tp: 26520.0000 - fp: 15768.0000 - tn: 13788.0000 - fn: 3036.0000 - accuracy: 0.6819 - precision: 0.6271 - recall: 0.8973 - auc: 0.7323 - prc: 0.6742\n",
      "Epoch 43/300\n",
      "1848/1848 [==============================] - 16s 9ms/step - loss: 0.6662 - tp: 26538.0000 - fp: 15821.0000 - tn: 13735.0000 - fn: 3018.0000 - accuracy: 0.6813 - precision: 0.6265 - recall: 0.8979 - auc: 0.7310 - prc: 0.6710\n",
      "Epoch 44/300\n",
      "1848/1848 [==============================] - 11s 6ms/step - loss: 0.5797 - tp: 26847.0000 - fp: 15982.0000 - tn: 13574.0000 - fn: 2709.0000 - accuracy: 0.6838 - precision: 0.6268 - recall: 0.9083 - auc: 0.7339 - prc: 0.6730\n",
      "Epoch 45/300\n",
      "1848/1848 [==============================] - 9s 5ms/step - loss: 0.6635 - tp: 26889.0000 - fp: 16117.0000 - tn: 13439.0000 - fn: 2667.0000 - accuracy: 0.6822 - precision: 0.6252 - recall: 0.9098 - auc: 0.7324 - prc: 0.6734\n",
      "Epoch 46/300\n",
      "1848/1848 [==============================] - 9s 5ms/step - loss: 0.5667 - tp: 27020.0000 - fp: 16148.0000 - tn: 13408.0000 - fn: 2536.0000 - accuracy: 0.6839 - precision: 0.6259 - recall: 0.9142 - auc: 0.7332 - prc: 0.6742\n",
      "Epoch 47/300\n",
      "1848/1848 [==============================] - 8s 5ms/step - loss: 1.4292 - tp: 26952.0000 - fp: 16037.0000 - tn: 13519.0000 - fn: 2604.0000 - accuracy: 0.6846 - precision: 0.6270 - recall: 0.9119 - auc: 0.7358 - prc: 0.6753\n",
      "Epoch 48/300\n",
      "1848/1848 [==============================] - 8s 4ms/step - loss: 0.5654 - tp: 26612.0000 - fp: 15574.0000 - tn: 13982.0000 - fn: 2944.0000 - accuracy: 0.6867 - precision: 0.6308 - recall: 0.9004 - auc: 0.7374 - prc: 0.6775\n",
      "Epoch 49/300\n",
      "1848/1848 [==============================] - 12s 6ms/step - loss: 0.5680 - tp: 26795.0000 - fp: 15950.0000 - tn: 13606.0000 - fn: 2761.0000 - accuracy: 0.6835 - precision: 0.6269 - recall: 0.9066 - auc: 0.7352 - prc: 0.6762\n",
      "Epoch 50/300\n",
      "1848/1848 [==============================] - 13s 7ms/step - loss: 1.2072 - tp: 26693.0000 - fp: 15600.0000 - tn: 13956.0000 - fn: 2863.0000 - accuracy: 0.6877 - precision: 0.6311 - recall: 0.9031 - auc: 0.7382 - prc: 0.6803\n",
      "Epoch 51/300\n",
      "1848/1848 [==============================] - 11s 6ms/step - loss: 1.6716 - tp: 26544.0000 - fp: 15520.0000 - tn: 14036.0000 - fn: 3012.0000 - accuracy: 0.6865 - precision: 0.6310 - recall: 0.8981 - auc: 0.7356 - prc: 0.6757\n",
      "Epoch 52/300\n",
      "1848/1848 [==============================] - 9s 5ms/step - loss: 0.9045 - tp: 26405.0000 - fp: 15498.0000 - tn: 14058.0000 - fn: 3151.0000 - accuracy: 0.6845 - precision: 0.6301 - recall: 0.8934 - auc: 0.7368 - prc: 0.6790\n",
      "Epoch 53/300\n",
      "1848/1848 [==============================] - 8s 4ms/step - loss: 0.5703 - tp: 26574.0000 - fp: 15773.0000 - tn: 13783.0000 - fn: 2982.0000 - accuracy: 0.6827 - precision: 0.6275 - recall: 0.8991 - auc: 0.7371 - prc: 0.6787\n",
      "Epoch 54/300\n",
      "1848/1848 [==============================] - 7s 4ms/step - loss: 0.6345 - tp: 26758.0000 - fp: 15788.0000 - tn: 13768.0000 - fn: 2798.0000 - accuracy: 0.6856 - precision: 0.6289 - recall: 0.9053 - auc: 0.7395 - prc: 0.6817\n",
      "Epoch 55/300\n",
      "1848/1848 [==============================] - 8s 4ms/step - loss: 3.7150 - tp: 26673.0000 - fp: 15525.0000 - tn: 14031.0000 - fn: 2883.0000 - accuracy: 0.6886 - precision: 0.6321 - recall: 0.9025 - auc: 0.7389 - prc: 0.6803\n",
      "Epoch 56/300\n",
      "1848/1848 [==============================] - 6s 3ms/step - loss: 1.1784 - tp: 26492.0000 - fp: 15355.0000 - tn: 14201.0000 - fn: 3064.0000 - accuracy: 0.6884 - precision: 0.6331 - recall: 0.8963 - auc: 0.7406 - prc: 0.6813\n",
      "Epoch 57/300\n",
      "1848/1848 [==============================] - 5s 3ms/step - loss: 0.5645 - tp: 26702.0000 - fp: 15596.0000 - tn: 13960.0000 - fn: 2854.0000 - accuracy: 0.6879 - precision: 0.6313 - recall: 0.9034 - auc: 0.7399 - prc: 0.6802\n",
      "Epoch 58/300\n",
      "1848/1848 [==============================] - 7s 4ms/step - loss: 1.7803 - tp: 26722.0000 - fp: 15688.0000 - tn: 13868.0000 - fn: 2834.0000 - accuracy: 0.6867 - precision: 0.6301 - recall: 0.9041 - auc: 0.7383 - prc: 0.6793\n",
      "Epoch 59/300\n",
      "1848/1848 [==============================] - 5s 3ms/step - loss: 0.7121 - tp: 26541.0000 - fp: 15299.0000 - tn: 14257.0000 - fn: 3015.0000 - accuracy: 0.6902 - precision: 0.6343 - recall: 0.8980 - auc: 0.7401 - prc: 0.6821\n",
      "Epoch 60/300\n",
      "1848/1848 [==============================] - 5s 3ms/step - loss: 0.7315 - tp: 26488.0000 - fp: 15270.0000 - tn: 14286.0000 - fn: 3068.0000 - accuracy: 0.6898 - precision: 0.6343 - recall: 0.8962 - auc: 0.7410 - prc: 0.6813\n",
      "Epoch 61/300\n",
      "1848/1848 [==============================] - 4s 2ms/step - loss: 0.7237 - tp: 26308.0000 - fp: 15184.0000 - tn: 14372.0000 - fn: 3248.0000 - accuracy: 0.6882 - precision: 0.6340 - recall: 0.8901 - auc: 0.7358 - prc: 0.6772\n",
      "Epoch 62/300\n",
      "1848/1848 [==============================] - 4s 2ms/step - loss: 0.5725 - tp: 26230.0000 - fp: 15043.0000 - tn: 14513.0000 - fn: 3326.0000 - accuracy: 0.6893 - precision: 0.6355 - recall: 0.8875 - auc: 0.7383 - prc: 0.6793\n",
      "Epoch 63/300\n",
      "1848/1848 [==============================] - 4s 2ms/step - loss: 0.5673 - tp: 26377.0000 - fp: 15364.0000 - tn: 14192.0000 - fn: 3179.0000 - accuracy: 0.6863 - precision: 0.6319 - recall: 0.8924 - auc: 0.7385 - prc: 0.6800\n",
      "Epoch 64/300\n",
      "1848/1848 [==============================] - 6s 3ms/step - loss: 0.5680 - tp: 26951.0000 - fp: 15870.0000 - tn: 13686.0000 - fn: 2605.0000 - accuracy: 0.6875 - precision: 0.6294 - recall: 0.9119 - auc: 0.7382 - prc: 0.6777\n",
      "Epoch 65/300\n",
      "1848/1848 [==============================] - 7s 4ms/step - loss: 0.5617 - tp: 26993.0000 - fp: 15759.0000 - tn: 13797.0000 - fn: 2563.0000 - accuracy: 0.6900 - precision: 0.6314 - recall: 0.9133 - auc: 0.7425 - prc: 0.6829\n",
      "Epoch 66/300\n",
      "1848/1848 [==============================] - 6s 3ms/step - loss: 0.5750 - tp: 27009.0000 - fp: 15820.0000 - tn: 13736.0000 - fn: 2547.0000 - accuracy: 0.6893 - precision: 0.6306 - recall: 0.9138 - auc: 0.7426 - prc: 0.6849\n",
      "Epoch 67/300\n",
      "1848/1848 [==============================] - 6s 3ms/step - loss: 0.6871 - tp: 26858.0000 - fp: 15606.0000 - tn: 13950.0000 - fn: 2698.0000 - accuracy: 0.6904 - precision: 0.6325 - recall: 0.9087 - auc: 0.7461 - prc: 0.6862\n",
      "Epoch 68/300\n",
      "1848/1848 [==============================] - 5s 3ms/step - loss: 1.4921 - tp: 26842.0000 - fp: 15710.0000 - tn: 13846.0000 - fn: 2714.0000 - accuracy: 0.6883 - precision: 0.6308 - recall: 0.9082 - auc: 0.7412 - prc: 0.6832\n",
      "Epoch 69/300\n",
      "1848/1848 [==============================] - 6s 3ms/step - loss: 0.5599 - tp: 27004.0000 - fp: 15694.0000 - tn: 13862.0000 - fn: 2552.0000 - accuracy: 0.6913 - precision: 0.6324 - recall: 0.9137 - auc: 0.7466 - prc: 0.6887\n",
      "Epoch 70/300\n",
      "1848/1848 [==============================] - 7s 4ms/step - loss: 0.8953 - tp: 26943.0000 - fp: 15748.0000 - tn: 13808.0000 - fn: 2613.0000 - accuracy: 0.6894 - precision: 0.6311 - recall: 0.9116 - auc: 0.7447 - prc: 0.6881\n",
      "Epoch 71/300\n",
      "1848/1848 [==============================] - 6s 3ms/step - loss: 0.5732 - tp: 26549.0000 - fp: 15159.0000 - tn: 14397.0000 - fn: 3007.0000 - accuracy: 0.6927 - precision: 0.6365 - recall: 0.8983 - auc: 0.7456 - prc: 0.6871\n",
      "Epoch 72/300\n",
      "1848/1848 [==============================] - 6s 3ms/step - loss: 0.5689 - tp: 26444.0000 - fp: 15031.0000 - tn: 14525.0000 - fn: 3112.0000 - accuracy: 0.6931 - precision: 0.6376 - recall: 0.8947 - auc: 0.7457 - prc: 0.6875\n",
      "Epoch 73/300\n",
      "1848/1848 [==============================] - 6s 3ms/step - loss: 0.5983 - tp: 26598.0000 - fp: 15241.0000 - tn: 14315.0000 - fn: 2958.0000 - accuracy: 0.6921 - precision: 0.6357 - recall: 0.8999 - auc: 0.7452 - prc: 0.6849\n",
      "Epoch 74/300\n",
      "1848/1848 [==============================] - 5s 3ms/step - loss: 1.0004 - tp: 26729.0000 - fp: 15339.0000 - tn: 14217.0000 - fn: 2827.0000 - accuracy: 0.6927 - precision: 0.6354 - recall: 0.9044 - auc: 0.7474 - prc: 0.6889\n",
      "Epoch 75/300\n",
      "1848/1848 [==============================] - 4s 2ms/step - loss: 0.7819 - tp: 26684.0000 - fp: 16254.0000 - tn: 13302.0000 - fn: 2872.0000 - accuracy: 0.6764 - precision: 0.6215 - recall: 0.9028 - auc: 0.7282 - prc: 0.6697\n",
      "Epoch 76/300\n",
      "1848/1848 [==============================] - 5s 3ms/step - loss: 0.5819 - tp: 26720.0000 - fp: 16703.0000 - tn: 12853.0000 - fn: 2836.0000 - accuracy: 0.6695 - precision: 0.6153 - recall: 0.9040 - auc: 0.7277 - prc: 0.6721\n",
      "Epoch 77/300\n",
      "1848/1848 [==============================] - 5s 3ms/step - loss: 11.7012 - tp: 26422.0000 - fp: 15353.0000 - tn: 14203.0000 - fn: 3134.0000 - accuracy: 0.6873 - precision: 0.6325 - recall: 0.8940 - auc: 0.7417 - prc: 0.6837\n",
      "Epoch 78/300\n",
      "1848/1848 [==============================] - 5s 2ms/step - loss: 0.7230 - tp: 26604.0000 - fp: 15323.0000 - tn: 14233.0000 - fn: 2952.0000 - accuracy: 0.6908 - precision: 0.6345 - recall: 0.9001 - auc: 0.7461 - prc: 0.6880\n",
      "Epoch 79/300\n",
      "1848/1848 [==============================] - 5s 3ms/step - loss: 0.5580 - tp: 26781.0000 - fp: 15394.0000 - tn: 14162.0000 - fn: 2775.0000 - accuracy: 0.6926 - precision: 0.6350 - recall: 0.9061 - auc: 0.7480 - prc: 0.6896\n",
      "Epoch 80/300\n",
      "1848/1848 [==============================] - 4s 2ms/step - loss: 0.7355 - tp: 26766.0000 - fp: 15444.0000 - tn: 14112.0000 - fn: 2790.0000 - accuracy: 0.6915 - precision: 0.6341 - recall: 0.9056 - auc: 0.7487 - prc: 0.6902\n",
      "Epoch 81/300\n",
      "1848/1848 [==============================] - 5s 3ms/step - loss: 0.8487 - tp: 26597.0000 - fp: 15163.0000 - tn: 14393.0000 - fn: 2959.0000 - accuracy: 0.6934 - precision: 0.6369 - recall: 0.8999 - auc: 0.7499 - prc: 0.6910\n",
      "Epoch 82/300\n",
      "1848/1848 [==============================] - 5s 2ms/step - loss: 1.1965 - tp: 26507.0000 - fp: 16105.0000 - tn: 13451.0000 - fn: 3049.0000 - accuracy: 0.6760 - precision: 0.6221 - recall: 0.8968 - auc: 0.7249 - prc: 0.6585\n",
      "Epoch 83/300\n",
      "1848/1848 [==============================] - 5s 3ms/step - loss: 0.7513 - tp: 26626.0000 - fp: 17273.0000 - tn: 12283.0000 - fn: 2930.0000 - accuracy: 0.6582 - precision: 0.6065 - recall: 0.9009 - auc: 0.7180 - prc: 0.6646\n",
      "Epoch 84/300\n",
      "1848/1848 [==============================] - 6s 3ms/step - loss: 0.5749 - tp: 26646.0000 - fp: 16242.0000 - tn: 13314.0000 - fn: 2910.0000 - accuracy: 0.6760 - precision: 0.6213 - recall: 0.9015 - auc: 0.7359 - prc: 0.6809\n",
      "Epoch 85/300\n",
      "1848/1848 [==============================] - 4s 2ms/step - loss: 0.5658 - tp: 26632.0000 - fp: 15555.0000 - tn: 14001.0000 - fn: 2924.0000 - accuracy: 0.6874 - precision: 0.6313 - recall: 0.9011 - auc: 0.7420 - prc: 0.6886\n",
      "Epoch 86/300\n",
      "1848/1848 [==============================] - 4s 2ms/step - loss: 5.1247 - tp: 26543.0000 - fp: 15727.0000 - tn: 13829.0000 - fn: 3013.0000 - accuracy: 0.6830 - precision: 0.6279 - recall: 0.8981 - auc: 0.7376 - prc: 0.6779\n",
      "Epoch 87/300\n",
      "1848/1848 [==============================] - 5s 3ms/step - loss: 0.6092 - tp: 26292.0000 - fp: 15270.0000 - tn: 14286.0000 - fn: 3264.0000 - accuracy: 0.6865 - precision: 0.6326 - recall: 0.8896 - auc: 0.7416 - prc: 0.6854\n",
      "Epoch 88/300\n",
      "1848/1848 [==============================] - 5s 3ms/step - loss: 1.5766 - tp: 27238.0000 - fp: 16338.0000 - tn: 13218.0000 - fn: 2318.0000 - accuracy: 0.6844 - precision: 0.6251 - recall: 0.9216 - auc: 0.7400 - prc: 0.6833\n",
      "Epoch 89/300\n",
      "1848/1848 [==============================] - 6s 3ms/step - loss: 0.5659 - tp: 27394.0000 - fp: 16679.0000 - tn: 12877.0000 - fn: 2162.0000 - accuracy: 0.6813 - precision: 0.6216 - recall: 0.9269 - auc: 0.7380 - prc: 0.6807\n",
      "Epoch 90/300\n",
      "1848/1848 [==============================] - 9s 5ms/step - loss: 0.6010 - tp: 27403.0000 - fp: 16499.0000 - tn: 13057.0000 - fn: 2153.0000 - accuracy: 0.6845 - precision: 0.6242 - recall: 0.9272 - auc: 0.7425 - prc: 0.6846\n",
      "Epoch 91/300\n",
      "1848/1848 [==============================] - 7s 4ms/step - loss: 2.3914 - tp: 26909.0000 - fp: 15910.0000 - tn: 13646.0000 - fn: 2647.0000 - accuracy: 0.6861 - precision: 0.6284 - recall: 0.9104 - auc: 0.7411 - prc: 0.6816\n",
      "Epoch 92/300\n",
      "1848/1848 [==============================] - 10s 6ms/step - loss: 0.7556 - tp: 26967.0000 - fp: 15928.0000 - tn: 13628.0000 - fn: 2589.0000 - accuracy: 0.6867 - precision: 0.6287 - recall: 0.9124 - auc: 0.7451 - prc: 0.6890\n",
      "Epoch 93/300\n",
      "1848/1848 [==============================] - 8s 5ms/step - loss: 5.4693 - tp: 27058.0000 - fp: 15975.0000 - tn: 13581.0000 - fn: 2498.0000 - accuracy: 0.6875 - precision: 0.6288 - recall: 0.9155 - auc: 0.7467 - prc: 0.6912\n",
      "Epoch 94/300\n",
      "1848/1848 [==============================] - 7s 4ms/step - loss: 0.5601 - tp: 27003.0000 - fp: 15894.0000 - tn: 13662.0000 - fn: 2553.0000 - accuracy: 0.6879 - precision: 0.6295 - recall: 0.9136 - auc: 0.7451 - prc: 0.6869\n",
      "Epoch 95/300\n",
      "1848/1848 [==============================] - 7s 4ms/step - loss: 1.1264 - tp: 26535.0000 - fp: 15296.0000 - tn: 14260.0000 - fn: 3021.0000 - accuracy: 0.6901 - precision: 0.6343 - recall: 0.8978 - auc: 0.7454 - prc: 0.6882\n",
      "Epoch 96/300\n",
      "1848/1848 [==============================] - 7s 4ms/step - loss: 0.6081 - tp: 26571.0000 - fp: 15171.0000 - tn: 14385.0000 - fn: 2985.0000 - accuracy: 0.6929 - precision: 0.6366 - recall: 0.8990 - auc: 0.7456 - prc: 0.6841\n",
      "Epoch 97/300\n",
      "1848/1848 [==============================] - 8s 4ms/step - loss: 0.9123 - tp: 26448.0000 - fp: 15742.0000 - tn: 13814.0000 - fn: 3108.0000 - accuracy: 0.6811 - precision: 0.6269 - recall: 0.8948 - auc: 0.7325 - prc: 0.6682\n",
      "Epoch 98/300\n",
      "1848/1848 [==============================] - 8s 5ms/step - loss: 0.5849 - tp: 26156.0000 - fp: 15348.0000 - tn: 14208.0000 - fn: 3400.0000 - accuracy: 0.6828 - precision: 0.6302 - recall: 0.8850 - auc: 0.7241 - prc: 0.6591\n",
      "Epoch 99/300\n",
      "1846/1848 [============================>.] - ETA: 0s - loss: 0.5746 - tp: 26100.0000 - fp: 15234.0000 - tn: 14305.0000 - fn: 3433.0000 - accuracy: 0.6840 - precision: 0.6314 - recall: 0.8838 - auc: 0.7358 - prc: 0.6751Restoring model weights from the end of the best epoch: 79.\n",
      "1848/1848 [==============================] - 9s 5ms/step - loss: 0.5745 - tp: 26122.0000 - fp: 15241.0000 - tn: 14315.0000 - fn: 3434.0000 - accuracy: 0.6841 - precision: 0.6315 - recall: 0.8838 - auc: 0.7359 - prc: 0.6752\n",
      "Epoch 99: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe7e75c2cd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model.fit(X_train_smt, y_train_smt, callbacks = [early_stopping], epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3315dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fe7e9298cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "792/792 [==============================] - 5s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "#Using the trained model, the prediction is done on the test set\n",
    "dnn_preds_smt = dnn_model.predict(X_test_smt)\n",
    "dnn_preds_smt = np.round(dnn_preds_smt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f82cd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.66      0.74     12667\n",
      "           1       0.72      0.88      0.79     12667\n",
      "\n",
      "    accuracy                           0.77     25334\n",
      "   macro avg       0.78      0.77      0.77     25334\n",
      "weighted avg       0.78      0.77      0.77     25334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Display the classification report of the model out of prediction using the test data\n",
    "print(classification_report(y_test_smt,dnn_preds_smt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92389f77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5abb9e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to display the confusion matrix\n",
    "def plot_cm(labels, predictions, p=0.5):\n",
    "    cm = confusion_matrix(labels, predictions > p)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])\n",
    "    print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "    print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])\n",
    "    print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])\n",
    "    print('Total Fraudulent Transactions: ', np.sum(cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "138779b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legitimate Transactions Detected (True Negatives):  8320\n",
      "Legitimate Transactions Incorrectly Detected (False Positives):  4347\n",
      "Fraudulent Transactions Missed (False Negatives):  1488\n",
      "Fraudulent Transactions Detected (True Positives):  11179\n",
      "Total Fraudulent Transactions:  12667\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cm(y_test_smt, dnn_preds_smt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a9a0e6",
   "metadata": {},
   "source": [
    "# Saving the trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d37910f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fe7e67a98c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fe7e7aaea70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "# Calling `save('my_model')` creates a SavedModel folder `dnn_model`.\n",
    "dnn_model.save(\"weekly_dnn_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c67e928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edcd4e12",
   "metadata": {},
   "source": [
    "# Sample prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f371f082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, record):\n",
    "    k = np.array(record).reshape(1,69)\n",
    "    prediction = int(np.round(dnn_model.predict(k))[0][0])\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "402c0737",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample record to predict\n",
    "k = np.array(X_test_smt.iloc[1]).reshape(1,69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab59b762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.        ,  1.        , 57.37102434, 16.94058534, 11.27089431,\n",
       "         2.34178861,  2.34178861,  0.        ,  0.        ,  9.86835772,\n",
       "         5.86835772,  0.        ,  1.31642278,  0.42644878,  0.20556748,\n",
       "         0.67049431,  0.50024066,  0.42125529,  0.53973334,  0.23873171,\n",
       "         0.16265691,  0.36720976,  5.65821139,  2.        , 46.9747642 ,\n",
       "        14.44552847,  6.91268292,  1.68357722,  1.68357722,  0.13671544,\n",
       "         0.13671544,  6.03417886,  5.00881303,  0.        ,  0.65821139,\n",
       "         0.28164228,  0.14632846,  0.55518049,  0.43441952,  0.26986667,\n",
       "         0.55289757,  0.28822439,  0.17949268,  0.54834472,  7.        ,\n",
       "         1.        , 65.16848776, 17.00881303, 14.40747972,  2.65821139,\n",
       "         3.        ,  0.68357722,  0.68357722, 12.51375616,  5.23791872,\n",
       "         0.        ,  1.65821139,  0.40670244,  0.24847805,  0.5978374 ,\n",
       "         0.46074797,  0.37518049,  0.50024066,  0.29138862,  0.21873171,\n",
       "         0.52201626,  1.22014489,  0.87982344,  0.72120902]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99e5a7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict using the loaded saved model\n",
    "reconstructed_model = keras.models.load_model(\"weekly_dnn_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e53bdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 152ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(reconstructed_model,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d04e22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "super-env",
   "language": "python",
   "name": "super-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
