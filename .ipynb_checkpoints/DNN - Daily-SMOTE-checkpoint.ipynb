{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dfbc098",
   "metadata": {},
   "source": [
    "# Importing the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1fd236b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import tempfile\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "22ea679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (15, 18)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3592ec4",
   "metadata": {},
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cefaf45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nr. sessions</th>\n",
       "      <th>total km</th>\n",
       "      <th>km Z3-4</th>\n",
       "      <th>km Z5-T1-T2</th>\n",
       "      <th>km sprinting</th>\n",
       "      <th>strength training</th>\n",
       "      <th>hours alternative</th>\n",
       "      <th>perceived exertion</th>\n",
       "      <th>perceived trainingSuccess</th>\n",
       "      <th>perceived recovery</th>\n",
       "      <th>...</th>\n",
       "      <th>km Z5-T1-T2.6</th>\n",
       "      <th>km sprinting.6</th>\n",
       "      <th>strength training.6</th>\n",
       "      <th>hours alternative.6</th>\n",
       "      <th>perceived exertion.6</th>\n",
       "      <th>perceived trainingSuccess.6</th>\n",
       "      <th>perceived recovery.6</th>\n",
       "      <th>Athlete ID</th>\n",
       "      <th>injury</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   nr. sessions  total km  km Z3-4  km Z5-T1-T2  km sprinting  \\\n",
       "0             1       5.8      0.0          0.6           1.2   \n",
       "1             0       0.0      0.0          0.0           0.0   \n",
       "2             1       0.0      0.0          0.0           0.0   \n",
       "3             0       0.0      0.0          0.0           0.0   \n",
       "4             1       0.0      0.0          0.0           0.0   \n",
       "\n",
       "   strength training  hours alternative  perceived exertion  \\\n",
       "0                0.0               0.00                0.11   \n",
       "1                0.0               0.00               -0.01   \n",
       "2                1.0               0.00                0.10   \n",
       "3                0.0               0.00               -0.01   \n",
       "4                0.0               1.08                0.08   \n",
       "\n",
       "   perceived trainingSuccess  perceived recovery  ...  km Z5-T1-T2.6  \\\n",
       "0                       0.00                0.18  ...            0.0   \n",
       "1                      -0.01               -0.01  ...            0.5   \n",
       "2                       0.00                0.17  ...            0.0   \n",
       "3                      -0.01               -0.01  ...            0.0   \n",
       "4                       0.00                0.18  ...            0.0   \n",
       "\n",
       "   km sprinting.6  strength training.6  hours alternative.6  \\\n",
       "0             0.0                  0.0                  1.0   \n",
       "1             1.2                  0.0                  0.0   \n",
       "2             0.0                  0.0                  0.0   \n",
       "3             0.0                  1.0                  0.0   \n",
       "4             0.0                  0.0                  0.0   \n",
       "\n",
       "   perceived exertion.6  perceived trainingSuccess.6  perceived recovery.6  \\\n",
       "0                  0.10                         0.00                  0.15   \n",
       "1                  0.10                         0.00                  0.17   \n",
       "2                 -0.01                        -0.01                 -0.01   \n",
       "3                  0.10                         0.00                  0.17   \n",
       "4                  0.11                         0.00                  0.17   \n",
       "\n",
       "   Athlete ID  injury  Date  \n",
       "0           0       0     0  \n",
       "1           0       0     1  \n",
       "2           0       0     2  \n",
       "3           0       0     3  \n",
       "4           0       0     4  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = tf.keras.utils\n",
    "raw_df = pd.read_csv('day_approach_maskedID_timeseries.csv')\n",
    "convert_dict = {'nr. sessions': int } #convert nr.sessions to int \n",
    "raw_df = raw_df.astype(convert_dict)\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ff9ceb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "    Total: 42766\n",
      "    Positive: 583 (1.36% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This section displays the percentage of the majority class\n",
    "neg, pos = np.bincount(raw_df['injury'])\n",
    "total = neg + pos\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da3bf02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "42761    71\n",
       "42762    71\n",
       "42763    71\n",
       "42764    71\n",
       "42765    71\n",
       "Name: Athlete ID, Length: 42766, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping the unnecessary columns/features\n",
    "cleaned_df = raw_df.copy()\n",
    "cleaned_df.pop('Date')\n",
    "cleaned_df.pop('Athlete ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e71874d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleaned_df.drop('injury', axis = 1)\n",
    "y = cleaned_df['injury']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a5a64fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42766, 70)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0fc169",
   "metadata": {},
   "source": [
    "# Applying Synthetic Minority Oversampling Technique (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33554ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is because the data is so imbalanced. The minority class is oversampled with new similar data is generated to compensate its minimal numbers\n",
    "smote_technique = SMOTE(sampling_strategy='minority')\n",
    "X_smt, y_smt = smote_technique.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9945a7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    42183\n",
       "1    42183\n",
       "Name: injury, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_smt.value_counts() #class counts now match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01270776",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data is split to Train and test \n",
    "X_train_smt, X_test_smt, y_train_smt, y_test_smt = train_test_split(X_smt, y_smt, test_size=0.3, random_state=15, stratify=y_smt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a226a1",
   "metadata": {},
   "source": [
    "# Defining the Deep Nearal Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbb0f0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-17 13:39:25.669507: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "dnn_model = keras.Sequential([\n",
    "    keras.layers.Dense(16, input_shape=(70,), activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(8, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='min',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e751c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a49aa7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model compliation\n",
    "dnn_model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b80d36e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fe66f59d950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1846/1846 [==============================] - 10s 3ms/step - loss: 0.7267 - tp: 18362.0000 - fp: 14070.0000 - tn: 15458.0000 - fn: 11166.0000 - accuracy: 0.5727 - precision: 0.5662 - recall: 0.6219 - auc: 0.5950 - prc: 0.5489\n",
      "Epoch 2/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.6065 - tp: 24601.0000 - fp: 14879.0000 - tn: 14649.0000 - fn: 4927.0000 - accuracy: 0.6646 - precision: 0.6231 - recall: 0.8331 - auc: 0.7050 - prc: 0.6507\n",
      "Epoch 3/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5711 - tp: 25203.0000 - fp: 13349.0000 - tn: 16179.0000 - fn: 4325.0000 - accuracy: 0.7007 - precision: 0.6537 - recall: 0.8535 - auc: 0.7416 - prc: 0.6820\n",
      "Epoch 4/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5489 - tp: 25582.0000 - fp: 12610.0000 - tn: 16918.0000 - fn: 3946.0000 - accuracy: 0.7197 - precision: 0.6698 - recall: 0.8664 - auc: 0.7618 - prc: 0.6995\n",
      "Epoch 5/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5290 - tp: 25888.0000 - fp: 11996.0000 - tn: 17532.0000 - fn: 3640.0000 - accuracy: 0.7352 - precision: 0.6833 - recall: 0.8767 - auc: 0.7821 - prc: 0.7242\n",
      "Epoch 6/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5155 - tp: 26028.0000 - fp: 11667.0000 - tn: 17861.0000 - fn: 3500.0000 - accuracy: 0.7432 - precision: 0.6905 - recall: 0.8815 - auc: 0.7908 - prc: 0.7332\n",
      "Epoch 7/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5060 - tp: 26115.0000 - fp: 11397.0000 - tn: 18131.0000 - fn: 3413.0000 - accuracy: 0.7492 - precision: 0.6962 - recall: 0.8844 - auc: 0.7985 - prc: 0.7425\n",
      "Epoch 8/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4979 - tp: 26162.0000 - fp: 10995.0000 - tn: 18533.0000 - fn: 3366.0000 - accuracy: 0.7568 - precision: 0.7041 - recall: 0.8860 - auc: 0.8055 - prc: 0.7504\n",
      "Epoch 9/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4886 - tp: 26388.0000 - fp: 10857.0000 - tn: 18671.0000 - fn: 3140.0000 - accuracy: 0.7630 - precision: 0.7085 - recall: 0.8937 - auc: 0.8130 - prc: 0.7602\n",
      "Epoch 10/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4828 - tp: 26484.0000 - fp: 10652.0000 - tn: 18876.0000 - fn: 3044.0000 - accuracy: 0.7681 - precision: 0.7132 - recall: 0.8969 - auc: 0.8178 - prc: 0.7653\n",
      "Epoch 11/300\n",
      "1846/1846 [==============================] - 5s 2ms/step - loss: 0.4767 - tp: 26629.0000 - fp: 10602.0000 - tn: 18926.0000 - fn: 2899.0000 - accuracy: 0.7714 - precision: 0.7152 - recall: 0.9018 - auc: 0.8208 - prc: 0.7694\n",
      "Epoch 12/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4782 - tp: 26782.0000 - fp: 10890.0000 - tn: 18638.0000 - fn: 2746.0000 - accuracy: 0.7691 - precision: 0.7109 - recall: 0.9070 - auc: 0.8183 - prc: 0.7661\n",
      "Epoch 13/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4703 - tp: 26813.0000 - fp: 10529.0000 - tn: 18999.0000 - fn: 2715.0000 - accuracy: 0.7757 - precision: 0.7180 - recall: 0.9081 - auc: 0.8252 - prc: 0.7761\n",
      "Epoch 14/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4646 - tp: 26962.0000 - fp: 10474.0000 - tn: 19054.0000 - fn: 2566.0000 - accuracy: 0.7792 - precision: 0.7202 - recall: 0.9131 - auc: 0.8278 - prc: 0.7778\n",
      "Epoch 15/300\n",
      "1846/1846 [==============================] - 5s 2ms/step - loss: 0.4662 - tp: 26876.0000 - fp: 10458.0000 - tn: 19070.0000 - fn: 2652.0000 - accuracy: 0.7780 - precision: 0.7199 - recall: 0.9102 - auc: 0.8282 - prc: 0.7808\n",
      "Epoch 16/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4631 - tp: 26984.0000 - fp: 10463.0000 - tn: 19065.0000 - fn: 2544.0000 - accuracy: 0.7798 - precision: 0.7206 - recall: 0.9138 - auc: 0.8313 - prc: 0.7839\n",
      "Epoch 17/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4565 - tp: 27032.0000 - fp: 10257.0000 - tn: 19271.0000 - fn: 2496.0000 - accuracy: 0.7841 - precision: 0.7249 - recall: 0.9155 - auc: 0.8353 - prc: 0.7881\n",
      "Epoch 18/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4537 - tp: 27106.0000 - fp: 10181.0000 - tn: 19347.0000 - fn: 2422.0000 - accuracy: 0.7866 - precision: 0.7270 - recall: 0.9180 - auc: 0.8348 - prc: 0.7868\n",
      "Epoch 19/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4520 - tp: 27172.0000 - fp: 10145.0000 - tn: 19383.0000 - fn: 2356.0000 - accuracy: 0.7883 - precision: 0.7281 - recall: 0.9202 - auc: 0.8358 - prc: 0.7876\n",
      "Epoch 20/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4524 - tp: 27158.0000 - fp: 10243.0000 - tn: 19285.0000 - fn: 2370.0000 - accuracy: 0.7864 - precision: 0.7261 - recall: 0.9197 - auc: 0.8361 - prc: 0.7880\n",
      "Epoch 21/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4494 - tp: 27161.0000 - fp: 10083.0000 - tn: 19445.0000 - fn: 2367.0000 - accuracy: 0.7892 - precision: 0.7293 - recall: 0.9198 - auc: 0.8391 - prc: 0.7944\n",
      "Epoch 22/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4472 - tp: 27294.0000 - fp: 10177.0000 - tn: 19351.0000 - fn: 2234.0000 - accuracy: 0.7898 - precision: 0.7284 - recall: 0.9243 - auc: 0.8402 - prc: 0.7970\n",
      "Epoch 23/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4471 - tp: 27211.0000 - fp: 10102.0000 - tn: 19426.0000 - fn: 2317.0000 - accuracy: 0.7897 - precision: 0.7293 - recall: 0.9215 - auc: 0.8405 - prc: 0.7970\n",
      "Epoch 24/300\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.4453 - tp: 27269.0000 - fp: 10074.0000 - tn: 19454.0000 - fn: 2259.0000 - accuracy: 0.7912 - precision: 0.7302 - recall: 0.9235 - auc: 0.8418 - prc: 0.7976\n",
      "Epoch 25/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4451 - tp: 27342.0000 - fp: 10126.0000 - tn: 19402.0000 - fn: 2186.0000 - accuracy: 0.7915 - precision: 0.7297 - recall: 0.9260 - auc: 0.8408 - prc: 0.7960\n",
      "Epoch 26/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4408 - tp: 27284.0000 - fp: 9936.0000 - tn: 19592.0000 - fn: 2244.0000 - accuracy: 0.7938 - precision: 0.7330 - recall: 0.9240 - auc: 0.8439 - prc: 0.8005\n",
      "Epoch 27/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4449 - tp: 27315.0000 - fp: 10228.0000 - tn: 19300.0000 - fn: 2213.0000 - accuracy: 0.7893 - precision: 0.7276 - recall: 0.9251 - auc: 0.8406 - prc: 0.7948\n",
      "Epoch 28/300\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.4354 - tp: 27438.0000 - fp: 9845.0000 - tn: 19683.0000 - fn: 2090.0000 - accuracy: 0.7979 - precision: 0.7359 - recall: 0.9292 - auc: 0.8467 - prc: 0.8026\n",
      "Epoch 29/300\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.4391 - tp: 27404.0000 - fp: 9936.0000 - tn: 19592.0000 - fn: 2124.0000 - accuracy: 0.7958 - precision: 0.7339 - recall: 0.9281 - auc: 0.8462 - prc: 0.8015\n",
      "Epoch 30/300\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.4371 - tp: 27320.0000 - fp: 9850.0000 - tn: 19678.0000 - fn: 2208.0000 - accuracy: 0.7958 - precision: 0.7350 - recall: 0.9252 - auc: 0.8473 - prc: 0.8044\n",
      "Epoch 31/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4354 - tp: 27440.0000 - fp: 9908.0000 - tn: 19620.0000 - fn: 2088.0000 - accuracy: 0.7969 - precision: 0.7347 - recall: 0.9293 - auc: 0.8480 - prc: 0.8054\n",
      "Epoch 32/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4339 - tp: 27394.0000 - fp: 9751.0000 - tn: 19777.0000 - fn: 2134.0000 - accuracy: 0.7988 - precision: 0.7375 - recall: 0.9277 - auc: 0.8496 - prc: 0.8067\n",
      "Epoch 33/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1846/1846 [==============================] - 5s 2ms/step - loss: 0.4318 - tp: 27439.0000 - fp: 9811.0000 - tn: 19717.0000 - fn: 2089.0000 - accuracy: 0.7985 - precision: 0.7366 - recall: 0.9293 - auc: 0.8494 - prc: 0.8080\n",
      "Epoch 34/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4318 - tp: 27468.0000 - fp: 9799.0000 - tn: 19729.0000 - fn: 2060.0000 - accuracy: 0.7992 - precision: 0.7371 - recall: 0.9302 - auc: 0.8507 - prc: 0.8074\n",
      "Epoch 35/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4293 - tp: 27476.0000 - fp: 9718.0000 - tn: 19810.0000 - fn: 2052.0000 - accuracy: 0.8007 - precision: 0.7387 - recall: 0.9305 - auc: 0.8514 - prc: 0.8071\n",
      "Epoch 36/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4288 - tp: 27484.0000 - fp: 9637.0000 - tn: 19891.0000 - fn: 2044.0000 - accuracy: 0.8022 - precision: 0.7404 - recall: 0.9308 - auc: 0.8518 - prc: 0.8085\n",
      "Epoch 37/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4297 - tp: 27567.0000 - fp: 9788.0000 - tn: 19740.0000 - fn: 1961.0000 - accuracy: 0.8011 - precision: 0.7380 - recall: 0.9336 - auc: 0.8498 - prc: 0.8044\n",
      "Epoch 38/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4260 - tp: 27544.0000 - fp: 9718.0000 - tn: 19810.0000 - fn: 1984.0000 - accuracy: 0.8018 - precision: 0.7392 - recall: 0.9328 - auc: 0.8536 - prc: 0.8106\n",
      "Epoch 39/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4289 - tp: 27556.0000 - fp: 9805.0000 - tn: 19723.0000 - fn: 1972.0000 - accuracy: 0.8006 - precision: 0.7376 - recall: 0.9332 - auc: 0.8518 - prc: 0.8098\n",
      "Epoch 40/300\n",
      "1846/1846 [==============================] - 5s 2ms/step - loss: 0.4255 - tp: 27535.0000 - fp: 9629.0000 - tn: 19899.0000 - fn: 1993.0000 - accuracy: 0.8032 - precision: 0.7409 - recall: 0.9325 - auc: 0.8541 - prc: 0.8108\n",
      "Epoch 41/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4246 - tp: 27542.0000 - fp: 9644.0000 - tn: 19884.0000 - fn: 1986.0000 - accuracy: 0.8031 - precision: 0.7407 - recall: 0.9327 - auc: 0.8556 - prc: 0.8146\n",
      "Epoch 42/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4233 - tp: 27636.0000 - fp: 9602.0000 - tn: 19926.0000 - fn: 1892.0000 - accuracy: 0.8054 - precision: 0.7421 - recall: 0.9359 - auc: 0.8551 - prc: 0.8117\n",
      "Epoch 43/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4250 - tp: 27645.0000 - fp: 9666.0000 - tn: 19862.0000 - fn: 1883.0000 - accuracy: 0.8044 - precision: 0.7409 - recall: 0.9362 - auc: 0.8540 - prc: 0.8103\n",
      "Epoch 44/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4229 - tp: 27577.0000 - fp: 9563.0000 - tn: 19965.0000 - fn: 1951.0000 - accuracy: 0.8050 - precision: 0.7425 - recall: 0.9339 - auc: 0.8554 - prc: 0.8129\n",
      "Epoch 45/300\n",
      "1846/1846 [==============================] - 5s 2ms/step - loss: 0.4222 - tp: 27652.0000 - fp: 9597.0000 - tn: 19931.0000 - fn: 1876.0000 - accuracy: 0.8057 - precision: 0.7424 - recall: 0.9365 - auc: 0.8548 - prc: 0.8131\n",
      "Epoch 46/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4220 - tp: 27647.0000 - fp: 9604.0000 - tn: 19924.0000 - fn: 1881.0000 - accuracy: 0.8055 - precision: 0.7422 - recall: 0.9363 - auc: 0.8558 - prc: 0.8136\n",
      "Epoch 47/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4211 - tp: 27633.0000 - fp: 9562.0000 - tn: 19966.0000 - fn: 1895.0000 - accuracy: 0.8060 - precision: 0.7429 - recall: 0.9358 - auc: 0.8557 - prc: 0.8127\n",
      "Epoch 48/300\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.4189 - tp: 27669.0000 - fp: 9487.0000 - tn: 20041.0000 - fn: 1859.0000 - accuracy: 0.8079 - precision: 0.7447 - recall: 0.9370 - auc: 0.8577 - prc: 0.8177\n",
      "Epoch 49/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4167 - tp: 27734.0000 - fp: 9466.0000 - tn: 20062.0000 - fn: 1794.0000 - accuracy: 0.8093 - precision: 0.7455 - recall: 0.9392 - auc: 0.8579 - prc: 0.8155\n",
      "Epoch 50/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4187 - tp: 27691.0000 - fp: 9493.0000 - tn: 20035.0000 - fn: 1837.0000 - accuracy: 0.8081 - precision: 0.7447 - recall: 0.9378 - auc: 0.8582 - prc: 0.8165\n",
      "Epoch 51/300\n",
      "1846/1846 [==============================] - 5s 2ms/step - loss: 0.4199 - tp: 27700.0000 - fp: 9570.0000 - tn: 19958.0000 - fn: 1828.0000 - accuracy: 0.8070 - precision: 0.7432 - recall: 0.9381 - auc: 0.8557 - prc: 0.8124\n",
      "Epoch 52/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4196 - tp: 27646.0000 - fp: 9518.0000 - tn: 20010.0000 - fn: 1882.0000 - accuracy: 0.8070 - precision: 0.7439 - recall: 0.9363 - auc: 0.8577 - prc: 0.8143\n",
      "Epoch 53/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4145 - tp: 27648.0000 - fp: 9309.0000 - tn: 20219.0000 - fn: 1880.0000 - accuracy: 0.8105 - precision: 0.7481 - recall: 0.9363 - auc: 0.8620 - prc: 0.8216\n",
      "Epoch 54/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4179 - tp: 27706.0000 - fp: 9556.0000 - tn: 19972.0000 - fn: 1822.0000 - accuracy: 0.8073 - precision: 0.7435 - recall: 0.9383 - auc: 0.8579 - prc: 0.8154\n",
      "Epoch 55/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4179 - tp: 27698.0000 - fp: 9490.0000 - tn: 20038.0000 - fn: 1830.0000 - accuracy: 0.8083 - precision: 0.7448 - recall: 0.9380 - auc: 0.8580 - prc: 0.8148\n",
      "Epoch 56/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4179 - tp: 27669.0000 - fp: 9412.0000 - tn: 20116.0000 - fn: 1859.0000 - accuracy: 0.8091 - precision: 0.7462 - recall: 0.9370 - auc: 0.8589 - prc: 0.8153\n",
      "Epoch 57/300\n",
      "1846/1846 [==============================] - 5s 2ms/step - loss: 0.4163 - tp: 27647.0000 - fp: 9378.0000 - tn: 20150.0000 - fn: 1881.0000 - accuracy: 0.8094 - precision: 0.7467 - recall: 0.9363 - auc: 0.8612 - prc: 0.8180\n",
      "Epoch 58/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4147 - tp: 27717.0000 - fp: 9318.0000 - tn: 20210.0000 - fn: 1811.0000 - accuracy: 0.8116 - precision: 0.7484 - recall: 0.9387 - auc: 0.8606 - prc: 0.8176\n",
      "Epoch 59/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4169 - tp: 27779.0000 - fp: 9522.0000 - tn: 20006.0000 - fn: 1749.0000 - accuracy: 0.8091 - precision: 0.7447 - recall: 0.9408 - auc: 0.8580 - prc: 0.8155\n",
      "Epoch 60/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4164 - tp: 27708.0000 - fp: 9391.0000 - tn: 20137.0000 - fn: 1820.0000 - accuracy: 0.8102 - precision: 0.7469 - recall: 0.9384 - auc: 0.8605 - prc: 0.8177\n",
      "Epoch 61/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4151 - tp: 27755.0000 - fp: 9474.0000 - tn: 20054.0000 - fn: 1773.0000 - accuracy: 0.8096 - precision: 0.7455 - recall: 0.9400 - auc: 0.8595 - prc: 0.8174\n",
      "Epoch 62/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4147 - tp: 27705.0000 - fp: 9421.0000 - tn: 20107.0000 - fn: 1823.0000 - accuracy: 0.8096 - precision: 0.7462 - recall: 0.9383 - auc: 0.8612 - prc: 0.8198\n",
      "Epoch 63/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4130 - tp: 27789.0000 - fp: 9426.0000 - tn: 20102.0000 - fn: 1739.0000 - accuracy: 0.8109 - precision: 0.7467 - recall: 0.9411 - auc: 0.8615 - prc: 0.8187\n",
      "Epoch 64/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4131 - tp: 27792.0000 - fp: 9478.0000 - tn: 20050.0000 - fn: 1736.0000 - accuracy: 0.8101 - precision: 0.7457 - recall: 0.9412 - auc: 0.8607 - prc: 0.8191\n",
      "Epoch 65/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4141 - tp: 27758.0000 - fp: 9426.0000 - tn: 20102.0000 - fn: 1770.0000 - accuracy: 0.8104 - precision: 0.7465 - recall: 0.9401 - auc: 0.8606 - prc: 0.8177\n",
      "Epoch 66/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4115 - tp: 27779.0000 - fp: 9304.0000 - tn: 20224.0000 - fn: 1749.0000 - accuracy: 0.8128 - precision: 0.7491 - recall: 0.9408 - auc: 0.8621 - prc: 0.8203\n",
      "Epoch 67/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.4124 - tp: 27731.0000 - fp: 9333.0000 - tn: 20195.0000 - fn: 1797.0000 - accuracy: 0.8115 - precision: 0.7482 - recall: 0.9391 - auc: 0.8610 - prc: 0.8180\n",
      "Epoch 68/300\n",
      "1846/1846 [==============================] - 9s 5ms/step - loss: 0.4134 - tp: 27754.0000 - fp: 9399.0000 - tn: 20129.0000 - fn: 1774.0000 - accuracy: 0.8108 - precision: 0.7470 - recall: 0.9399 - auc: 0.8606 - prc: 0.8184\n",
      "Epoch 69/300\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.4132 - tp: 27746.0000 - fp: 9423.0000 - tn: 20105.0000 - fn: 1782.0000 - accuracy: 0.8103 - precision: 0.7465 - recall: 0.9397 - auc: 0.8603 - prc: 0.8186\n",
      "Epoch 70/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4115 - tp: 27799.0000 - fp: 9367.0000 - tn: 20161.0000 - fn: 1729.0000 - accuracy: 0.8121 - precision: 0.7480 - recall: 0.9414 - auc: 0.8635 - prc: 0.8203\n",
      "Epoch 71/300\n",
      "1846/1846 [==============================] - 10s 5ms/step - loss: 0.4098 - tp: 27834.0000 - fp: 9313.0000 - tn: 20215.0000 - fn: 1694.0000 - accuracy: 0.8136 - precision: 0.7493 - recall: 0.9426 - auc: 0.8628 - prc: 0.8205\n",
      "Epoch 72/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4107 - tp: 27846.0000 - fp: 9412.0000 - tn: 20116.0000 - fn: 1682.0000 - accuracy: 0.8121 - precision: 0.7474 - recall: 0.9430 - auc: 0.8614 - prc: 0.8197\n",
      "Epoch 73/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4122 - tp: 27797.0000 - fp: 9393.0000 - tn: 20135.0000 - fn: 1731.0000 - accuracy: 0.8116 - precision: 0.7474 - recall: 0.9414 - auc: 0.8617 - prc: 0.8175\n",
      "Epoch 74/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4111 - tp: 27875.0000 - fp: 9407.0000 - tn: 20121.0000 - fn: 1653.0000 - accuracy: 0.8127 - precision: 0.7477 - recall: 0.9440 - auc: 0.8612 - prc: 0.8174\n",
      "Epoch 75/300\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.4127 - tp: 27765.0000 - fp: 9382.0000 - tn: 20146.0000 - fn: 1763.0000 - accuracy: 0.8113 - precision: 0.7474 - recall: 0.9403 - auc: 0.8621 - prc: 0.8193\n",
      "Epoch 76/300\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.4107 - tp: 27827.0000 - fp: 9298.0000 - tn: 20230.0000 - fn: 1701.0000 - accuracy: 0.8138 - precision: 0.7495 - recall: 0.9424 - auc: 0.8617 - prc: 0.8185\n",
      "Epoch 77/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4065 - tp: 27854.0000 - fp: 9197.0000 - tn: 20331.0000 - fn: 1674.0000 - accuracy: 0.8159 - precision: 0.7518 - recall: 0.9433 - auc: 0.8651 - prc: 0.8211\n",
      "Epoch 78/300\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.4093 - tp: 27825.0000 - fp: 9371.0000 - tn: 20157.0000 - fn: 1703.0000 - accuracy: 0.8125 - precision: 0.7481 - recall: 0.9423 - auc: 0.8618 - prc: 0.8191\n",
      "Epoch 79/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4127 - tp: 27833.0000 - fp: 9468.0000 - tn: 20060.0000 - fn: 1695.0000 - accuracy: 0.8110 - precision: 0.7462 - recall: 0.9426 - auc: 0.8602 - prc: 0.8164\n",
      "Epoch 80/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4115 - tp: 27813.0000 - fp: 9342.0000 - tn: 20186.0000 - fn: 1715.0000 - accuracy: 0.8128 - precision: 0.7486 - recall: 0.9419 - auc: 0.8622 - prc: 0.8160\n",
      "Epoch 81/300\n",
      "1846/1846 [==============================] - 4s 2ms/step - loss: 0.4108 - tp: 27830.0000 - fp: 9415.0000 - tn: 20113.0000 - fn: 1698.0000 - accuracy: 0.8118 - precision: 0.7472 - recall: 0.9425 - auc: 0.8634 - prc: 0.8205\n",
      "Epoch 82/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4099 - tp: 27859.0000 - fp: 9399.0000 - tn: 20129.0000 - fn: 1669.0000 - accuracy: 0.8126 - precision: 0.7477 - recall: 0.9435 - auc: 0.8620 - prc: 0.8216\n",
      "Epoch 83/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4072 - tp: 27911.0000 - fp: 9338.0000 - tn: 20190.0000 - fn: 1617.0000 - accuracy: 0.8145 - precision: 0.7493 - recall: 0.9452 - auc: 0.8648 - prc: 0.8241\n",
      "Epoch 84/300\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4086 - tp: 27925.0000 - fp: 9349.0000 - tn: 20179.0000 - fn: 1603.0000 - accuracy: 0.8145 - precision: 0.7492 - recall: 0.9457 - auc: 0.8627 - prc: 0.8204\n",
      "Epoch 85/300\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.4104 - tp: 27817.0000 - fp: 9381.0000 - tn: 20147.0000 - fn: 1711.0000 - accuracy: 0.8122 - precision: 0.7478 - recall: 0.9421 - auc: 0.8618 - prc: 0.8186\n",
      "Epoch 86/300\n",
      "1846/1846 [==============================] - 4s 2ms/step - loss: 0.4079 - tp: 27847.0000 - fp: 9200.0000 - tn: 20328.0000 - fn: 1681.0000 - accuracy: 0.8158 - precision: 0.7517 - recall: 0.9431 - auc: 0.8656 - prc: 0.8232\n",
      "Epoch 87/300\n",
      "1843/1846 [============================>.] - ETA: 0s - loss: 0.4091 - tp: 27786.0000 - fp: 9301.0000 - tn: 20185.0000 - fn: 1704.0000 - accuracy: 0.8134 - precision: 0.7492 - recall: 0.9422 - auc: 0.8633 - prc: 0.8201Restoring model weights from the end of the best epoch: 77.\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4090 - tp: 27821.0000 - fp: 9307.0000 - tn: 20221.0000 - fn: 1707.0000 - accuracy: 0.8135 - precision: 0.7493 - recall: 0.9422 - auc: 0.8635 - prc: 0.8201\n",
      "Epoch 87: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe69a6b9b10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model.fit(X_train_smt, y_train_smt, callbacks = [early_stopping], epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c18b91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fe6714449e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "791/791 [==============================] - 2s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#Using the trained model, the prediction is done on the test set\n",
    "dnn_preds_smt = dnn_model.predict(X_test_smt)\n",
    "dnn_preds_smt = np.round(dnn_preds_smt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "407605b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.84      0.88     12655\n",
      "           1       0.86      0.93      0.89     12655\n",
      "\n",
      "    accuracy                           0.89     25310\n",
      "   macro avg       0.89      0.89      0.89     25310\n",
      "weighted avg       0.89      0.89      0.89     25310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Display the classification report of the model out of prediction using the test data\n",
    "print(classification_report(y_test_smt,dnn_preds_smt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db5e7a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "815b13c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to display the confusion matrix\n",
    "def plot_cm(labels, predictions, p=0.5):\n",
    "    cm = confusion_matrix(labels, predictions > p)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])\n",
    "    print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "    print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])\n",
    "    print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])\n",
    "    print('Total Fraudulent Transactions: ', np.sum(cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a42a9d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legitimate Transactions Detected (True Negatives):  10683\n",
      "Legitimate Transactions Incorrectly Detected (False Positives):  1972\n",
      "Fraudulent Transactions Missed (False Negatives):  841\n",
      "Fraudulent Transactions Detected (True Positives):  11814\n",
      "Total Fraudulent Transactions:  12655\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cm(y_test_smt, dnn_preds_smt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bc25d4",
   "metadata": {},
   "source": [
    "# Saving the trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f64fd4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fe676b0a680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fe676af28c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "# Calling `save('my_model')` creates a SavedModel folder `dnn_model`.\n",
    "dnn_model.save(\"dnn_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d79154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ddbf0b1",
   "metadata": {},
   "source": [
    "# Sample prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2eceba86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, record):\n",
    "    k = np.array(record).reshape(1,70)\n",
    "    prediction = int(np.round(dnn_model.predict(k))[0][0])\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7cd8b8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample record to predict\n",
    "k = np.array(X_test_smt.iloc[1]).reshape(1,70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cbdb960b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict using the loaded saved model\n",
    "reconstructed_model = keras.models.load_model(\"dnn_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "469ed961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 69ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(reconstructed_model,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7502c9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "super-env",
   "language": "python",
   "name": "super-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
